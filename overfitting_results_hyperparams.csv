validation accuracy,0.7596464187341785,0.8068932343293607,0.8179592517971859,0.831516503815323,0.8333929428792226,0.83821215577826,0.8553587557377093,0.8558238667681328,0.8642350960915044,0.8558240999426753,0.8586450686166408,0.8717284797262443,0.8750043783527769,0.8725036637691724,0.8743718574486792,0.8710971730774544,0.871582924769586,0.8760889018720878,0.8793645423815819,0.8877752796482696,0.8846641337637925,0.8880933648706246,0.892611474607674,0.8891885554639058,0.8905846054629674,0.8885582253423421,0.8888765460067394,0.8952563020181887,0.8963597493333607,0.8944857342265378,0.8957349931037403,0.896824125315996,0.8965147873512794,0.8929256710682084,0.8958863951860438,0.9004137268439821,0.8919918130717468,0.8890310980239097,0.8962008308677867,0.8989963245569838
training accuracy,0.6386990932340403,0.7719590704752034,0.8048105755565974,0.8176086930190081,0.8246050208595397,0.8322767933743028,0.837125530098396,0.8438971876797842,0.8492308059708747,0.8571794427013956,0.8604009657867369,0.8620805954746056,0.8648515271354393,0.8682282824768747,0.8753810843563269,0.8764028283719043,0.8787057836914001,0.8807839247362953,0.8835552433164724,0.8840399508478296,0.8859967027745149,0.8906027063773582,0.891035894738868,0.8933915119749806,0.8964912560300717,0.8969416254429692,0.8977555592673412,0.899296765779438,0.901305624743563,0.9028641802533341,0.9029857223249786,0.9018944682888712,0.9044049098542668,0.9104493906525162,0.9096356218418198,0.9085793717710555,0.9087001699542092,0.9120428331877886,0.9126832888354907,0.9142770703097552
validation loss,0.4916970356459752,0.4260436093068517,0.3949740961775342,0.3806215371747255,0.37662669110935376,0.36266871338890605,0.33483902401446464,0.32537825898195083,0.3158871956282095,0.3135359614060235,0.3228214717962719,0.2948587594977755,0.290051932659371,0.2940978218588689,0.284453773412719,0.2982450587180342,0.2815213667328837,0.2740978733206644,0.26560290715871937,0.2643055313273188,0.265667311143155,0.26921295780551624,0.2631275063294549,0.2576432048444127,0.25588837699017136,0.25606436596820914,0.26310444077475076,0.2538646678801191,0.24277829487626873,0.25943352509632195,0.2502624708484148,0.2512791053973913,0.26300805329148236,0.2564787141388282,0.2716472625532112,0.25269383662801653,0.26403339386083935,0.26327700938327614,0.2532975186866432,0.2465543953077493
training loss,0.652956331329742,0.4672437805457778,0.42469333312423174,0.40309876864172445,0.38977780125231926,0.37091333456154485,0.356903382462317,0.3441123509687303,0.3340173339736054,0.3192252307677797,0.3092311767486239,0.3050901520837446,0.2951626043989317,0.2870401585343479,0.27891856631627115,0.27695434002173236,0.2713568144884772,0.26548909545671034,0.2599249297476225,0.2573221479392376,0.25136123837005453,0.2440418021280737,0.24423396086782828,0.2371042439027733,0.23482819228814486,0.23325930512960674,0.23137893425230677,0.22890266621903083,0.22199335786772875,0.2202414263172729,0.22142718727160876,0.21919893610717386,0.2178563773947984,0.2059554829014852,0.20591665842262055,0.20939911324168428,0.2097981632763708,0.20061582986269397,0.19888746226411938,0.19693907648677356
